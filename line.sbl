* LINE.SBL

*       Copyright 2017, David Shields
*       Licensed under the MIT license.

*       This file extends SPITBOL by adding support for creating and operating
*       on lines.

*	Lines can be just strings or, in some cases, a line is represented by a pair:

	data('line(mark,text')

*	where

*		_mark_ is defined by the value returned by an instance
*		of the _eval_ function ...

*		_text_ is the text of the line.

        define('reader(filename,expr)line,makr')               :(reader.end)




*       Return a sequence of the lines in the file specified by _filename_.
*	If _expr_ is not null, then _eval_ is called just
*	after each line is read, with the variable _pair_ set to
*	the associated pair. If _eval_ fails the line is skipped. 
*	Otherwise returns a new pair to be entered in the input 
*	sequence.


*READER*
reader

        differ(filename) input(.file,g.channel.temp,filename):s(reader.opened)
        out('unable to open reader file ' filename '.') :(freturn)

reader.opened

        reader = map(1024)

reader.next

        map.add(map, (ident(filename) input, file))     :f(reader.eof)s(reader.next)

reader.eof

*       Here at end of file; close temporary file if one was needed.

        differ(filename) endfile(g.channel.temp)        :(return)

reader.end

	define('reader.string(str,delim)line')			:(reader.string.end)

*	Returns a sequence of the lines in _str_,
*	where the delimiter character _delim_ is used to mark 
*	the end of a line. One intended use of _reader.string_ 
*	is to assist in the construction of test programs.

reader.string

	delim = ident(delim) '/'
	reader.string = map.sequence()

reader.string.next

	str break(delim) . line delim =			:f(return)
	add(reader.string,line)				:(reader.string.next)

reader.string.end

        define('tokens(line)type,pos,text,lineno')                     (tokens.end)


*       Tokens scans _line_ and returns a table of the tokens in the line.
*       The table has keys from 1..n, where _n_ is the number of tokens found. The
*       key '#' gives the number of entries in the table, and is used for no other purpose.
*       For example, a scan of an empty line results in tokens['#'] having the value zero.

*       This function is an instance of what is called a tokensical scanner, or tokenizer,
*        which is the first stage in a programming language compiler, or for any program 
*       that processes text files with a specified structure.

*       Each token is represented as an instance of the datatype _token_ as follows:

        data('token(lineno,pos,type,text)'

*       where:
*               _lineno_        is the line number within the file;
*               _pos_           is the position of the first character of the token in the line;
*               _type_          is the token's type, as described below; and
*               _text_          is the text of the token.

*       The type is represented by a single character, as follows:

*               'c'             comment, indicated by asterisk (*) in the first column.
*                               The text consists of the entire line.
*               'i'             integer, consisting of one or more digits ('0123456789')
*               'l'             left opener, one of '(<[{'
*               'p'             punctation, one of '.;,?!', or single quote ('), or double quote ("),
*               'o'             other printable character, one of '~@#$%^&*_-+=`'.
                'q'             quoted string, starting witn '"', and continuing to the next instance of the opening quote character.
*               'r'             right closer, one of ')>]}'
*               's'             space, consistine of one or more spaces (spaces)
*               't'             tab character
*               'u'             unprintable character, for example control-k
*               'w'             word, consisting of one of more letters in upper or lower case or
*                               "'" or "_".

*       The longest possible string meeting the rules is used when building a token.
*       For example, 'abc' is just the word 'abc', not 'a' followed by 'bc', and so forth.

*       It is recommended that the tab character NOT be used as an abbreviation for one or more spaces
*       in the input file. If tabs are used, then _pos_ is ill-defined. If tabs are not used, then _pos_
*       indicates the true position in the line of the first character of the token, and so error messages
*       and references to the token will be exact. For example, _pos_ could be used to indicate where to
*       give emphasis to a token by underlining it, or enclosing it in '_' to generate markdown format, and so forth.



tokens  

        tokens = map.sequence()
        line '*'                                        :f(tokens.next)
        type = 'c'
        text = line                                                             
        line =                                          :(tokens.new)

tokens.next

        line ' '                                        :s(tokens.space)
        line any('0123456789')                          :s(tokens.integer)
        line any('(<[{')                                :s(tokens.left)
        line any('.;,?!')                               :s(tokens.punctuation)
        line '"'                                        :s(tokens.quote)
        line any('~@#$%^&*_-+=')                                        :s(tokens.other
        line any(')>]}')                                :s(tokens.right)
        line char(9)                                    :s(tokens.tab)
        line any(&lcase &ucase)                         :s(tokens.word)

*       Here for unprintable
                                                        :(tokens.unprintable)

tokens.integer

        type = 'i'
        line span('0123456789') . text =                :(tokens.new)

tokens.punctuation 

        type = 'p'                                       :(tokens.character)

tokens.other

        type = 'o'                                      :(tokens.character)

*tokens.other

        type = 'o'                                      :(tokens.character)

tokens.quote

        type = 'q'
        line '"' break('"') . text '"' =        
        text = '"' text '"'                             :(tokens.new)

tokens.right

        type = 'r'                                      :(tokens.character)

tokens.space

        type = 's'
        line span(' ')  . text =                        :(tokens.new)

tokens.tab

        type = 't'                                      :(tokens.character)

tokens.word

*FIX*
        type = 'w'
        line span(&ucase &lcase "_" "'"))) . text =      :(tokens.new)

map.sbl:1okens.tab

        type = 't'                                      :(tokens.character)

tokens.character

*       Here if token is single character.

        line len(1) . text                              :(tokens.new)

tokens.new

        map.add(tokens,token(lineno,pos,type,text))     :(tokens.next)

tokens.end

        define('words(line)word')                        :(words.end)

*       Return sequence of the words in line, fail if no words.

*WORDS*
words

        words = map()
        line = ' line ' '

words.next

        line break(' ') . word ' ' =                     :f(return)
        map.add(words,word)                             :(words.next)

words.end

       define('writer(lines)'       )                  :(writer.end)

*       Writes a sequence of the lines in the sequence _lines_
*	to standard output.

writer

	lines = copy(lines)
	map.loop(lines)

writer.next
	
	output = map.next(lines)				:f(return)s(writer.next)

writer.end

